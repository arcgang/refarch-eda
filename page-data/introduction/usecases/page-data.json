{"componentChunkName":"component---src-pages-introduction-usecases-index-mdx","path":"/introduction/usecases/","result":{"pageContext":{"frontmatter":{"title":"Generic Business Use Cases","description":"EDA Classical Technical Use Cases"},"relativePagePath":"/introduction/usecases/index.mdx","titleType":"append","MdxNode":{"id":"a1dfbe73-d632-5b08-97f9-cfc9b69ff535","children":[],"parent":"7316b5ed-1652-5fec-8eb8-07b77503ab0b","internal":{"content":"---\ntitle: Generic Business Use Cases\ndescription: EDA Classical Technical Use Cases\n---\n\nUpdated 04/19/2022\n\n## Business use cases\n\nIn recent years, due to the business demands for greater responsiveness and awareness of context in \nbusiness decisions, organizations have taken a more strategic approach to supporting EDA.\n\nWe have observed the following the main business justifications for adopting real-time processing, event-driven architecture.\n\n![](./images/hl-biz-cases.png)\n\n* **Response to events in real time**: Get visibility of events cross applications, even if they were not designed as event-producer\nand then act on those events, by deriving synthetic events or trigger business processes. Business are looking at better\nway to understand user's behavior on their on-line presence, and being able to act quickly for product recommendations,\npropose ad-hoc support, gather data for fraud detection, cause analysis of potential customer churn, fraud detection...\n* **Deliver responsive customer experiences**: This is also about scaling web applications, locate processing closer to the end users,\nbe resilient to underlying business services failure, separate read from write models, adoption reactive - manifesto while programming\nnew business services\n* **Brings real-time intelligence**: is about integrating analytics to real-time data streaming. Moving out of batch\nprocessing when it is relevant to compute aggregates on data in motion. This also includes embedding AI model, into the\nstreaming application. Intelligence also means rule based reasoning, and complex event processing helps to recognize\nevent patterns and act on them. The use \n\nEvent in 2022, a lot of companies are not aware of what's is going on inside the company and with their customer's interactions.\n\n## Technical use cases \n\nRecurring technical needs and use cases are specifics for adopting event-driven architecture. \nWe can list the following important concerns:\n\n![](./images/4-usecases.png)\n\n* **Communication layer:**  \n\n  * Adopt messaging and asynchronous communication between applications and \nmicroservices for loosely coupled services. Messaging helps exchanging\ndata between services and message brokers are needed to support the persistence and high availability\nto produce and consume those data. (See [this note](https://ibm-cloud-architecture.github.io/refarch-integration/service-mesh/readme/#asynchronous-loosely-coupled-solution-using-events) where we present a way to support a service mesh solution using asynchronous event).\nThe data are pushed as immutables record, or commands are sent with exactly once delivery. Reducing pull data approach. \n  * Pub/sub messaging for cloud native applications to improve communication inter microservices.\n  * Support Always-on services with asynchronous data replication.\n  * Expose data to any application to consume.\n  * Time decoupling is important and consumers fetch data when they want.\n\n* **Reactive systems:** to support reactive, responsive applications for addressing\nresiliency, scaling so adopting message buses.\n\n  * Adopt real-time processing moving out of batch processing when possible.\n\n* **Data Agility:**\n\n  * The distributed nature of cloud native applications, means we need to address subjects like availability, consistency and resilience to network partitioning. Data consitency could not be guarantee, without strong transaction support, but multi-cloud, multi data centers, \napplication allocations in different container orchestrator, means dealing with eventual consistency.\n  * Centralize online data pipeline to decouple applications and microservices.\n  * Monitor distributed applications to produce centralized feed of operational data.\n  * Logs collector from multiple services.\n  * Implement [event sourcing pattern](/patterns/event-sourcing/) out of the box, using configuration to keep message for a long time period. Data are replicated between brokers within the cluster and cross availability zones if needed.\n  * As data is visible in highly available manner, persisted in distributed broker cluster, those brokers\nare becoming data hub, data buffering for larger data pipeline processing.\n\n* **Near real-time analytics insights:**\n\n  * Compute real-time aggregates, time window based reasoning, and even complex event-processing which looks after event sequencing patterns.\n  * Aggregation of event coming from multiple producers.\n  * Look at event sequencing patterns\n  * Compute next best action from event streams\n\n\n","type":"Mdx","contentDigest":"d389591d7a0fa4357e72d18a50311c35","owner":"gatsby-plugin-mdx","counter":907},"frontmatter":{"title":"Generic Business Use Cases","description":"EDA Classical Technical Use Cases"},"exports":{},"rawBody":"---\ntitle: Generic Business Use Cases\ndescription: EDA Classical Technical Use Cases\n---\n\nUpdated 04/19/2022\n\n## Business use cases\n\nIn recent years, due to the business demands for greater responsiveness and awareness of context in \nbusiness decisions, organizations have taken a more strategic approach to supporting EDA.\n\nWe have observed the following the main business justifications for adopting real-time processing, event-driven architecture.\n\n![](./images/hl-biz-cases.png)\n\n* **Response to events in real time**: Get visibility of events cross applications, even if they were not designed as event-producer\nand then act on those events, by deriving synthetic events or trigger business processes. Business are looking at better\nway to understand user's behavior on their on-line presence, and being able to act quickly for product recommendations,\npropose ad-hoc support, gather data for fraud detection, cause analysis of potential customer churn, fraud detection...\n* **Deliver responsive customer experiences**: This is also about scaling web applications, locate processing closer to the end users,\nbe resilient to underlying business services failure, separate read from write models, adoption reactive - manifesto while programming\nnew business services\n* **Brings real-time intelligence**: is about integrating analytics to real-time data streaming. Moving out of batch\nprocessing when it is relevant to compute aggregates on data in motion. This also includes embedding AI model, into the\nstreaming application. Intelligence also means rule based reasoning, and complex event processing helps to recognize\nevent patterns and act on them. The use \n\nEvent in 2022, a lot of companies are not aware of what's is going on inside the company and with their customer's interactions.\n\n## Technical use cases \n\nRecurring technical needs and use cases are specifics for adopting event-driven architecture. \nWe can list the following important concerns:\n\n![](./images/4-usecases.png)\n\n* **Communication layer:**  \n\n  * Adopt messaging and asynchronous communication between applications and \nmicroservices for loosely coupled services. Messaging helps exchanging\ndata between services and message brokers are needed to support the persistence and high availability\nto produce and consume those data. (See [this note](https://ibm-cloud-architecture.github.io/refarch-integration/service-mesh/readme/#asynchronous-loosely-coupled-solution-using-events) where we present a way to support a service mesh solution using asynchronous event).\nThe data are pushed as immutables record, or commands are sent with exactly once delivery. Reducing pull data approach. \n  * Pub/sub messaging for cloud native applications to improve communication inter microservices.\n  * Support Always-on services with asynchronous data replication.\n  * Expose data to any application to consume.\n  * Time decoupling is important and consumers fetch data when they want.\n\n* **Reactive systems:** to support reactive, responsive applications for addressing\nresiliency, scaling so adopting message buses.\n\n  * Adopt real-time processing moving out of batch processing when possible.\n\n* **Data Agility:**\n\n  * The distributed nature of cloud native applications, means we need to address subjects like availability, consistency and resilience to network partitioning. Data consitency could not be guarantee, without strong transaction support, but multi-cloud, multi data centers, \napplication allocations in different container orchestrator, means dealing with eventual consistency.\n  * Centralize online data pipeline to decouple applications and microservices.\n  * Monitor distributed applications to produce centralized feed of operational data.\n  * Logs collector from multiple services.\n  * Implement [event sourcing pattern](/patterns/event-sourcing/) out of the box, using configuration to keep message for a long time period. Data are replicated between brokers within the cluster and cross availability zones if needed.\n  * As data is visible in highly available manner, persisted in distributed broker cluster, those brokers\nare becoming data hub, data buffering for larger data pipeline processing.\n\n* **Near real-time analytics insights:**\n\n  * Compute real-time aggregates, time window based reasoning, and even complex event-processing which looks after event sequencing patterns.\n  * Aggregation of event coming from multiple producers.\n  * Look at event sequencing patterns\n  * Compute next best action from event streams\n\n\n","fileAbsolutePath":"/home/runner/work/refarch-eda/refarch-eda/docs/src/pages/introduction/usecases/index.mdx"}}},"staticQueryHashes":["1364590287","137577622","137577622","2102389209","2102389209","2456312558","2746626797","2746626797","3018647132","3018647132","3037994772","3037994772","768070550"]}