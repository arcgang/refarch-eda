{"componentChunkName":"component---src-pages-scenarios-realtime-inventory-index-mdx","path":"/scenarios/realtime-inventory/","result":{"pageContext":{"frontmatter":{"description":"Scenarios / Realtime Inventory","title":"Scenarios / Realtime Inventory"},"relativePagePath":"/scenarios/realtime-inventory/index.mdx","titleType":"append","MdxNode":{"id":"645ba643-c2fb-5b45-9f6a-93fcb3400b19","children":[],"parent":"1397c2b6-79ae-57a1-adc3-d7c425fab022","internal":{"content":" \n\n\n\n### A little bit more on environments\n\nFor demonstration purpose, only the `rt-inventory-dev` environment is detailed. One ArgoCD app: [rt-inventory-dev-env](https://github.com/ibm-cloud-architecture/eda-rt-inventory-gitops/blob/main/config/argocd/rt-inventory-dev-env-app.yaml) is monitoring\n the folder [environments/rt-inventory-dev/env/overlays](https://github.com/ibm-cloud-architecture/eda-rt-inventory-gitops/tree/main/environments/rt-inventory-dev/env/overlays) which define the namespace and roles,... \nEach application of the solution are also monitored by an ArgoCD and their declarations are done using standard kubernetes manifests. Here is an exampe of app tree structure:\n\n```\n── store-inventory\n│   ├── base\n│   │   └── kustomization.yaml\n│   ├── kustomization.yaml\n│   ├── overlays\n│   │   └── kustomization.yaml\n│   └── services\n│       └── store-inventory\n│           ├── base\n│           │   ├── config\n│           │   │   ├── configmap.yaml\n│           │   │   ├── deployment.yaml\n│           │   │   ├── kustomization.yaml\n│           │   │   ├── rolebinding.yaml\n│           │   │   ├── route.yaml\n│           │   │   ├── service.yaml\n│           │   │   └── serviceaccount.yaml\n│           │   └── kustomization.yaml\n│           ├── kustomization.yaml\n│           └── overlays\n│               └── kustomization.yaml\n```\n\nThe last intesting part is to declare the products used within the Cloud Pak for Integration, and deployed in the context of\nthe respective environments. Everything is in `services` folder. The tree looks like below:\n\n```\n── apicurio\n│   ├── base\n│   │   ├── es-kafka-topics.yaml\n│   │   ├── kustomization.yaml\n│   │   └── registry.yaml\n│   └── overlays\n│       └── kustomization.yaml\n├── event-endpoint\n│   ├── base\n│   │   ├── eventendpointmanager-eepm-eda.yaml\n│   │   └── kustomization.yaml\n│   └── overlays\n│       ├── kustomization.yaml\n│       └── v10.0.4.0\n│           ├── kustomization.yaml\n│           └── patch-version.yaml\n├── ibm-eventstreams\n│   ├── base\n│   │   ├── es-topics.yaml\n│   │   ├── eventstreams-dev.yaml\n│   │   ├── kustomization.yaml\n│   │   ├── scram-user.yaml\n│   │   └── tls-user.yaml\n│   └── overlays\n│       ├── kustomization.yaml\n│       └── v10.5\n│           ├── kustomization.yaml\n│           └── patch-version.yaml\n├── ibm-mq\n│   ├── base\n│   │   ├── kustomization.yaml\n│   │   └── qmgr.yaml\n│   └── overlays\n│       ├── kustomization.yaml\n│       └── v9.2.4\n│           ├── kustomization.yaml\n│           └── patch-channel.yaml\n├── kconnect\n│   ├── README.md\n│   ├── kafka-connect.yaml\n│   ├── kafka-cos-sink-connector.yaml\n│   ├── kustomization.yaml\n│   └── mq-source.json\n└── kustomization.yaml\n```\n\nWith the public docker images, and the public GitOps repository, the solution can be deployed to an OpenShift cluster with or without Cloud Pak for Integration already deployed.\n\n\n\n### Install Yourself on OpenShift\n\nIt is possible to do a step by step deployment of the solution without any gitops deployment. This is more like a lab tutorial, where you can progress more slowly and verify\nthe result at each steps.\n\nGo to the `rt-inventory-gitops/ocp-demo-step-by-step` folder and follow the [README instructions](https://github.com/ibm-cloud-architecture/eda-rt-inventory-gitops/tree/main/ocp-demo-step-by-step) to make\na step by step approach creating records with the simulator, see them in MQ Queue, start the Kafka Connector MQ source, to move data to Event Streams topic, then\ndo the kafka streams processing. \n\n### Run with gitops on openshift\n\nIn this approach, we propose to use a GitOps repository and deploy the solution using few scripts and `oc` CLI commands.\nIn the figure below, all the components are deployed with OpenShift GitOps. The blue components are IBM product components like Event Streams and MQ operators and some other operators, like Elastic Search.\nThe green rectangles represent the microservices and kafka connectors source or sink deployed as part of the solution.\n\n![](./images/hl-view.png)\n\nSee next guided tour for GitOps approach.\n\n\n## Bootstrap GitOps\n\nBootstrapping GitOps is mostly to install the MQ, Event Streams, APIC Connect, OpenShift Gitops, and ElasticSearch operators, and do any pre-requisites like entitlement keys.\n\nWe prefer to keep the bootstrap instructions in the source repository, therefore follow [the up to date instructions](https://github.com/ibm-cloud-architecture/eda-rt-inventory-gitops#bootstrap-gitops) from the gitops main readme.\n\n## Deploy the Solution\n\nOnce operators are deployed. \n\n* Deploying the full solution is by starting ArgoCD app of apps:\n\n  ```sh\n  oc apply -k config/argocd\n  ```\n\n* Access the OpenShift GitOps (ArgoCD) console\n\n  ```sh\n   chrome https://$(oc get route openshift-gitops-server -o jsonpath='{.status.ingress[].host}'  -n openshift-gitops)\n   ```\n\nThe expected set of ArgoCD apps looks like (and all should be green):\n\n  ![](./images/rt-inv-argoapps.png)\n\n  * **rt-inventory-Argo-app** is an app of apps\n  * **rt-inventory-dev-env** is for the rt-inventory-dev namespace\n  * **rt-inventory-dev-services** is for event streams, kafka connect cluster and mq deployments in dev-env namespace\n  * **rt-inventory-store-simulator-app** is for the simulator app used in the demo.\n  * **rt-inventory-item-inventory** for the item aggregator application\n  * **rt-inventory-store-inventory** for the store aggregator application\n  * **rt-inventory-dev-eepm-service** for Event End Point management\n  * **rt-inventory-dev-elastic-svc** for Elastic Search deployment\n  * **rt-inventory-dv-kibana-svc** for Kibana\n\n* Verify pods\n\n```sh\n  oc project rt-inventory-dev\n  oc get pods\n\n  NAME                                         READY   STATUS    RESTARTS   AGE\n  dev-kafka-cruise-control-6d6bf8b774-99rwl    2/2     Running   0          4d\n  dev-kafka-entity-operator-75f7bc8f5c-x4vkt   3/3     Running   0          4d\n  dev-kafka-kafka-0                            1/1     Running   0          4d\n  dev-kafka-kafka-1                            1/1     Running   0          4d\n  dev-kafka-kafka-2                            1/1     Running   0          4d\n  dev-kafka-zookeeper-0                        1/1     Running   0          4d\n  dev-kafka-zookeeper-1                        1/1     Running   0          4d\n  dev-kafka-zookeeper-2                        1/1     Running   0          4d\n  item-inventory-669fd4fffc-4fvhk             1/1     Running   0          30h\n  store-inventory-7df98556ff-f2ndq            1/1     Running   0          29h\n  store-simulator-56f8958498-mvhp9             1/1     Running   0          4d\n  dev-entity-operator-74d7dc5cfb-ksv68                              3/3     Running     0          5d21h\n  dev-ibm-es-ac-reg-77bfbf84b9-qn8ln                                2/2     Running     0          5d21h\n  dev-ibm-es-admapi-6f6bcd465c-h8scj                                1/1     Running     0          5d21h\n  dev-ibm-es-metrics-9c4679cd-n5bb7                                 1/1     Running     0          5d21h\n  dev-ibm-es-recapi-775bf874b9-gqbdn                                1/1     Running     0          5d21h\n  dev-ibm-es-ui-5d488967d4-6v2tm                                    2/2     Running     0          5d21h\n  eda-eepm-mgmt-27885b45-postgres-55b548f64f-nqs6f                  0/1     Init:0/1    0          4d23h\n  eda-eepm-mgmt-27885b45-postgres-backrest-shared-repo-7b58fjdd7s   1/1     Running     0          12d\n  eda-eepm-mgmt-27885b45-postgres-pgbouncer-5575bc4595-c9zng        1/1     Running     0          12d\n  eda-kconnect-cluster-connect-78ccb7cc56-jh2ck                     1/1     Running     0          4d17h\n  elasticsearch-es-default-0                                        1/1     Running     0          36m\n  elasticsearch-es-default-1                                        1/1     Running     0          36m\n  elasticsearch-es-default-2                                        1/1     Running     0          36m\n  kibana-kb-67f4c87c65-9whwz                                        1/1     Running     0          36m\n  store-mq-ibm-mq-0                                                 1/1     Running     1          4d19h\n  ```\n\n\n","type":"Mdx","contentDigest":"3936099064805e4d1ebcd7ab117cf2e9","owner":"gatsby-plugin-mdx","counter":922},"frontmatter":{"description":"Scenarios / Realtime Inventory","title":"Scenarios / Realtime Inventory"},"exports":{},"rawBody":" \n\n\n\n### A little bit more on environments\n\nFor demonstration purpose, only the `rt-inventory-dev` environment is detailed. One ArgoCD app: [rt-inventory-dev-env](https://github.com/ibm-cloud-architecture/eda-rt-inventory-gitops/blob/main/config/argocd/rt-inventory-dev-env-app.yaml) is monitoring\n the folder [environments/rt-inventory-dev/env/overlays](https://github.com/ibm-cloud-architecture/eda-rt-inventory-gitops/tree/main/environments/rt-inventory-dev/env/overlays) which define the namespace and roles,... \nEach application of the solution are also monitored by an ArgoCD and their declarations are done using standard kubernetes manifests. Here is an exampe of app tree structure:\n\n```\n── store-inventory\n│   ├── base\n│   │   └── kustomization.yaml\n│   ├── kustomization.yaml\n│   ├── overlays\n│   │   └── kustomization.yaml\n│   └── services\n│       └── store-inventory\n│           ├── base\n│           │   ├── config\n│           │   │   ├── configmap.yaml\n│           │   │   ├── deployment.yaml\n│           │   │   ├── kustomization.yaml\n│           │   │   ├── rolebinding.yaml\n│           │   │   ├── route.yaml\n│           │   │   ├── service.yaml\n│           │   │   └── serviceaccount.yaml\n│           │   └── kustomization.yaml\n│           ├── kustomization.yaml\n│           └── overlays\n│               └── kustomization.yaml\n```\n\nThe last intesting part is to declare the products used within the Cloud Pak for Integration, and deployed in the context of\nthe respective environments. Everything is in `services` folder. The tree looks like below:\n\n```\n── apicurio\n│   ├── base\n│   │   ├── es-kafka-topics.yaml\n│   │   ├── kustomization.yaml\n│   │   └── registry.yaml\n│   └── overlays\n│       └── kustomization.yaml\n├── event-endpoint\n│   ├── base\n│   │   ├── eventendpointmanager-eepm-eda.yaml\n│   │   └── kustomization.yaml\n│   └── overlays\n│       ├── kustomization.yaml\n│       └── v10.0.4.0\n│           ├── kustomization.yaml\n│           └── patch-version.yaml\n├── ibm-eventstreams\n│   ├── base\n│   │   ├── es-topics.yaml\n│   │   ├── eventstreams-dev.yaml\n│   │   ├── kustomization.yaml\n│   │   ├── scram-user.yaml\n│   │   └── tls-user.yaml\n│   └── overlays\n│       ├── kustomization.yaml\n│       └── v10.5\n│           ├── kustomization.yaml\n│           └── patch-version.yaml\n├── ibm-mq\n│   ├── base\n│   │   ├── kustomization.yaml\n│   │   └── qmgr.yaml\n│   └── overlays\n│       ├── kustomization.yaml\n│       └── v9.2.4\n│           ├── kustomization.yaml\n│           └── patch-channel.yaml\n├── kconnect\n│   ├── README.md\n│   ├── kafka-connect.yaml\n│   ├── kafka-cos-sink-connector.yaml\n│   ├── kustomization.yaml\n│   └── mq-source.json\n└── kustomization.yaml\n```\n\nWith the public docker images, and the public GitOps repository, the solution can be deployed to an OpenShift cluster with or without Cloud Pak for Integration already deployed.\n\n\n\n### Install Yourself on OpenShift\n\nIt is possible to do a step by step deployment of the solution without any gitops deployment. This is more like a lab tutorial, where you can progress more slowly and verify\nthe result at each steps.\n\nGo to the `rt-inventory-gitops/ocp-demo-step-by-step` folder and follow the [README instructions](https://github.com/ibm-cloud-architecture/eda-rt-inventory-gitops/tree/main/ocp-demo-step-by-step) to make\na step by step approach creating records with the simulator, see them in MQ Queue, start the Kafka Connector MQ source, to move data to Event Streams topic, then\ndo the kafka streams processing. \n\n### Run with gitops on openshift\n\nIn this approach, we propose to use a GitOps repository and deploy the solution using few scripts and `oc` CLI commands.\nIn the figure below, all the components are deployed with OpenShift GitOps. The blue components are IBM product components like Event Streams and MQ operators and some other operators, like Elastic Search.\nThe green rectangles represent the microservices and kafka connectors source or sink deployed as part of the solution.\n\n![](./images/hl-view.png)\n\nSee next guided tour for GitOps approach.\n\n\n## Bootstrap GitOps\n\nBootstrapping GitOps is mostly to install the MQ, Event Streams, APIC Connect, OpenShift Gitops, and ElasticSearch operators, and do any pre-requisites like entitlement keys.\n\nWe prefer to keep the bootstrap instructions in the source repository, therefore follow [the up to date instructions](https://github.com/ibm-cloud-architecture/eda-rt-inventory-gitops#bootstrap-gitops) from the gitops main readme.\n\n## Deploy the Solution\n\nOnce operators are deployed. \n\n* Deploying the full solution is by starting ArgoCD app of apps:\n\n  ```sh\n  oc apply -k config/argocd\n  ```\n\n* Access the OpenShift GitOps (ArgoCD) console\n\n  ```sh\n   chrome https://$(oc get route openshift-gitops-server -o jsonpath='{.status.ingress[].host}'  -n openshift-gitops)\n   ```\n\nThe expected set of ArgoCD apps looks like (and all should be green):\n\n  ![](./images/rt-inv-argoapps.png)\n\n  * **rt-inventory-Argo-app** is an app of apps\n  * **rt-inventory-dev-env** is for the rt-inventory-dev namespace\n  * **rt-inventory-dev-services** is for event streams, kafka connect cluster and mq deployments in dev-env namespace\n  * **rt-inventory-store-simulator-app** is for the simulator app used in the demo.\n  * **rt-inventory-item-inventory** for the item aggregator application\n  * **rt-inventory-store-inventory** for the store aggregator application\n  * **rt-inventory-dev-eepm-service** for Event End Point management\n  * **rt-inventory-dev-elastic-svc** for Elastic Search deployment\n  * **rt-inventory-dv-kibana-svc** for Kibana\n\n* Verify pods\n\n```sh\n  oc project rt-inventory-dev\n  oc get pods\n\n  NAME                                         READY   STATUS    RESTARTS   AGE\n  dev-kafka-cruise-control-6d6bf8b774-99rwl    2/2     Running   0          4d\n  dev-kafka-entity-operator-75f7bc8f5c-x4vkt   3/3     Running   0          4d\n  dev-kafka-kafka-0                            1/1     Running   0          4d\n  dev-kafka-kafka-1                            1/1     Running   0          4d\n  dev-kafka-kafka-2                            1/1     Running   0          4d\n  dev-kafka-zookeeper-0                        1/1     Running   0          4d\n  dev-kafka-zookeeper-1                        1/1     Running   0          4d\n  dev-kafka-zookeeper-2                        1/1     Running   0          4d\n  item-inventory-669fd4fffc-4fvhk             1/1     Running   0          30h\n  store-inventory-7df98556ff-f2ndq            1/1     Running   0          29h\n  store-simulator-56f8958498-mvhp9             1/1     Running   0          4d\n  dev-entity-operator-74d7dc5cfb-ksv68                              3/3     Running     0          5d21h\n  dev-ibm-es-ac-reg-77bfbf84b9-qn8ln                                2/2     Running     0          5d21h\n  dev-ibm-es-admapi-6f6bcd465c-h8scj                                1/1     Running     0          5d21h\n  dev-ibm-es-metrics-9c4679cd-n5bb7                                 1/1     Running     0          5d21h\n  dev-ibm-es-recapi-775bf874b9-gqbdn                                1/1     Running     0          5d21h\n  dev-ibm-es-ui-5d488967d4-6v2tm                                    2/2     Running     0          5d21h\n  eda-eepm-mgmt-27885b45-postgres-55b548f64f-nqs6f                  0/1     Init:0/1    0          4d23h\n  eda-eepm-mgmt-27885b45-postgres-backrest-shared-repo-7b58fjdd7s   1/1     Running     0          12d\n  eda-eepm-mgmt-27885b45-postgres-pgbouncer-5575bc4595-c9zng        1/1     Running     0          12d\n  eda-kconnect-cluster-connect-78ccb7cc56-jh2ck                     1/1     Running     0          4d17h\n  elasticsearch-es-default-0                                        1/1     Running     0          36m\n  elasticsearch-es-default-1                                        1/1     Running     0          36m\n  elasticsearch-es-default-2                                        1/1     Running     0          36m\n  kibana-kb-67f4c87c65-9whwz                                        1/1     Running     0          36m\n  store-mq-ibm-mq-0                                                 1/1     Running     1          4d19h\n  ```\n\n\n","fileAbsolutePath":"/home/runner/work/refarch-eda/refarch-eda/docs/src/pages/scenarios/realtime-inventory/index.mdx"}}},"staticQueryHashes":["1364590287","137577622","137577622","2102389209","2102389209","2456312558","2746626797","2746626797","3018647132","3018647132","3037994772","3037994772","768070550"]}