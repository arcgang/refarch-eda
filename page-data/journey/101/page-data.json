{"componentChunkName":"component---src-pages-journey-101-index-mdx","path":"/journey/101/","result":{"pageContext":{"frontmatter":{"title":"Learning Journey - getting started (101 content)","description":"Learning the Basic of Event Streams, Event Driven Solution"},"relativePagePath":"/journey/101/index.mdx","titleType":"append","MdxNode":{"id":"d684cf47-f701-5a19-8096-3f302419368d","children":[],"parent":"da5ecd45-dabb-52bc-93fa-f64ed5c2eead","internal":{"content":"---\ntitle: Learning Journey - getting started (101 content)\ndescription: Learning the Basic of Event Streams, Event Driven Solution\n---\n\n<InlineNotification kind=\"warning\">\n<strong>Updated 10/12/2021 - Ready for consumption - Open Issue for request for improvement</strong>\n</InlineNotification>\n\nThis chapter is to get you understanding what is Event-Driven architecture,\nwhat is Kafka, how to consider Messaging as a service as a foundation for\nevent-driven solution, and getting started on IBM Event Streams and IBM MQ.\n\n<AnchorLinks>\n  <AnchorLink>Important concepts around Event-driven solution and Event-driven architecture</AnchorLink>\n  <AnchorLink>Understand Kafka technology</AnchorLink>\n  <AnchorLink>So what is IBM Event Streams?</AnchorLink>\n  <AnchorLink>Use Cases</AnchorLink>\n  <AnchorLink>Why microservices are becoming event-driven and why we should care?</AnchorLink>\n  <AnchorLink>Messaging as a service?</AnchorLink>\n  <AnchorLink>Fit for purpose</AnchorLink>\n  <AnchorLink>Event Streams environment sizing</AnchorLink>\n  <AnchorLink>Getting Started With Event Streams</AnchorLink>\n  <AnchorLink>Methodology: getting started on a good path</AnchorLink>\n  <AnchorLink>Frequently asked questions</AnchorLink>\n</AnchorLinks>\n\n## Important concepts around Event-driven solution and Event-driven architecture\n\nFirst to get an agreement on the [terms and definitions](/concepts/terms-and-definitions/) used in all \nthis body of knowledge content, with a clear definitions for `events`, `event streams`, `event backbone`, `event sources`....\n\nThe main up-to-date [reference architecture presentation is in this section](/introduction/reference-architecture/#event-driven-architecture) with all the component descriptions.\n\n ![hl-arch-ra](../../images/hl-arch-ra.png)\n\n\nThis architecture is built after a lot of customer engagements, projects, and review, and \nit is driven to support the [main technical most common use cases](/introduction/usecases/) \nwe observed for EDA adoption so far.\n\n## Understand Kafka technology\n\nYou may want to read from the [Kafka] documentation](https://kafka.apache.org/documentation/#intro_nutshell) to understand the main concepts, but we have\nalso summarized those into [this chapter](/technology/kafka-overview/) and if you like quick \nvideo, here is a seven minutes review of what Kafka is:\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/aj9CDZm0Glc\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n\nThe major building blocks are summarized in this diagram:\n\n![](./images/kafka-components.png)\n\nTo learn more about:\n\n* Kafka Cluster see [this 101 content](/technology/kafka-overview/#kafka-components)\n* For Producer introduction [see this section](/technology/kafka-producers/#understanding-kafka-producers)\n* For Consumer introduction [see this section](/technology/kafka-consumers/)\n* For [Kafka Connector framework introduction](/technology/kafka-connect/)\n\n## So what is IBM Event Streams?\n\nEvent Streams is the IBM packaging of Kafka for the Enterprise. It uses an award winner integrated user interface, kubernetes operator based on open source Strimzi, \nschema registry based on OpenSource and connectors. \nThe phylosophie is to bring together Open Source leading products to support event streaming solution developments on kubernetes platform. \nCombined with event-end point management, no-code integration and IBM MQ, Event Streams brings Kafka to the enterprise.\n\nIt is available as [a Managed Service](https://www.ibm.com/cloud/event-streams)\nor as part of Cloud Pak for integration. [See this developer.ibm.com article about Event Streams on Cloud](https://developer.ibm.com/articles/event-streams-fundamentals/?mhsrc=ibmsearch_a&mhq=ibm%20event%20streams) \nfor a quick introduction.\n\nThe Event Streams product documentation as part of **IBM Cloud Pak for Integration** is [here](https://ibm.github.io/event-streams/about/overview/).\n\n### Runnable demonstrations\n\n* You can install the product using the Operator Hub, IBM Catalog and the OpenShift console. \n[This lab](/technology/event-streams/es-cp4i/#install-event-streams-using-openshift-console) can help you get an environment up and running quickly.\n* You can then run the **Starter Application** as explained in [this tutorial](/technology/event-streams/es-cp4i/#run-starter-application). \n* You may need to demonstrate how to deploy Event Streams with CLI, and [this lab](/technology/event-streams/es-cp4i/#install-event-streams-using-clis) will teach you how to leverage our gitops repository\n* To go deeper in GitOps adoption and discussion, [this tutorial](/use-cases/gitops/) is using two public repositories to demonstrate how to do the automatic deployment of event streams\nand an event-driven solution.\n* Run a simple Kafka Streams and Event Stream demo for [real-time inventory](/scenarios/realtime-inventory/) using this demonstration scripts and GitOps repository.\n\n### Event streams resource requirements\n\nSee the [detailed tables](https://ibm.github.io/event-streams/installing/prerequisites/#helm-resource-requirements) in the product documentation.\n\n### Event Streams environment sizing\n\nA lot of information is available for sizing:\n\n* [Cloud Pak for integration system requirements](https://www.ibm.com/docs/en/cloud-paks/cp-integration/2021.3?topic=installation-system-requirements)\n* [Foundational service specifics](https://www.ibm.com/docs/en/cloud-paks/cp-integration/2021.3?topic=requirements-sizing-foundational-services)\n* [Event Streams resource requirements](https://ibm.github.io/event-streams/installing/prerequisites/)\n* Kafka has a [sizing tool (eventsizer)](https://eventsizer.io/) that may be questionable but some people are using it.\n\nBut in general starts small and then increase the number of nodes over time.\n\nMinimum for production is 5 brokers and 3 zookeepers.\n \n\n## Use Cases\n\nWe have different level of use cases in this repository: \n\nThe generic use cases which present the main drivers for EDA adoption are [summarized here](/introduction/usecases/). \n\nBut architects need to search and identify a set of key requirements to be supported by thier own EDA:\n\n* get visibility of the new data created by existing applications in near real-time to get better business insights and propose new business opportunities to the end-users / customers. \nThis means adopting data streaming, and intelligent query solutions.\n* integrate with existing transactional systems, and continue to do transaction processing while adopting eventual data consistency, characteristics of distributed systems. (Cloud-native serverless or microservices are distributed systems)\n* move to asynchronous communication between serverless and microservices, so they become more responsive, resilient, and scalable (characteristics of ‘Reactive applications’).\n* get loosely coupled but still understand the API contracts. API being synchronous (RES, SOAP) or async (queue and topic).\n* get clear visibility of data governance, with cataloging applications to be able to continuously assess which apps securely access what, with what intent.\n\n\nWe have done some reference implementations to illustrate the major EDA design patterns:\n\n| Scenario                           | Description         | Link        |\n| --------------------------------| ------------------  |:----------- |\n| Shipping fresh food over sea _(external)_ | The EDA solution implementation using event driven microservices in different language, and demonstrating different design patterns. | [EDA reference implementation solution](https://ibm-cloud-architecture.github.io/refarch-kc/)|\n| Vaccine delivery at scale _(external)_ | An EDA and cross cloud pak solution | [Vaccine delivery at scale](https://ibm-cloud-architecture.github.io/vaccine-solution-main/)\n| Real time anomaly detection _(external)_ | Develop and apply machine learning predictive model on event streams | [Refrigerator container anomaly detection solution](https://ibm-cloud-architecture.github.io/refarch-reefer-ml/)|\n\n## Why microservices are becoming event-driven and why we should care?\n\nThis [article](/advantages/microservice) explains why microservices are becoming event-driven \nand relates to some design patterns and potential microservice code structure.\n\n## Messaging as a service? \n\nYes EDA is not just Kafka, IBM MQ and Kafka should be part of any serious EDA deployment.\nThe main reasons are explained in [this fit for purpose section](/concepts/fit-to-purpose/#mq-versus-kafka) and in\nthe [messaging versus eventing presentation](/concepts/events-versus-messages/).\n\nAn introduction to MQ is summarized in [this note](/technology/mq/) in the 301 learning journey, developers need to get the [MQ developer badge](https://developer.ibm.com/learningpaths/ibm-mq-badge/)\nas it cover the basics for developing solution on top of MQ Broker.\n\n## Fit for purpose\n\nWe have a [general fit for purpose document](/concepts/fit-to-purpose/) that can help you reviewing messaging versus eventing,\nMQ versus Kafka, but also Kafka Streams versus Apache Flink.\n\n\n## Getting Started With Event Streams\n\n### With IBM Cloud\n\nThe most easy way to start is to create one `Event Streams on IBM Cloud` service instance,\nand then connect a starter application. See this [service at this URL](https://cloud.ibm.com/catalog/services/event-streams).\n\n### Running on you laptop\n\nAs a **developer**, you may want to start quickly playing with a local Kafka Broker and MQ Broker \non you own laptop. We have developed such compose files in [this gitops project](https://github.com/ibm-cloud-architecture/eda-gitops-catalog) under\nthe `RunLocally` folder.\n\n  ```sh\n  # Kafka based on strimzi image and MQ container\n  docker-compose -f maas-compose.yaml up &\n  # Kafka only\n  docker-compose -f kafka-compose.yaml up &\n  ```\nThe kafka images are based on Strimzi images, but act as Event Streams one. So any code developed and configured\non this image will run the same when deployed on OpenShift using Event Streams.\n\n### Running on OpenShift\n\nFinally if you have access to an OpenShift Cluster, version 4.7 +, you can deploy \nEvent Streams as part of IBM Cloud Pak for Integration very easily using the\nOpenShift Admin console.\n\nSee this simple [step by step tutorial here](/technology/event-streams/es-cp4i/) which covers\nhow to deployment and configuration an Event Streams cluster using the OpenShift Admin\n Console or the `oc CLI` and our manifest from our [EDA gitops catalog repository](https://github.com/ibm-cloud-architecture/eda-gitops-catalog).\n\n### Show and tell \n\nOnce you have deployed a cluster, access the administration console and use the\nvery good [getting started application](https://ibm.github.io/event-streams/getting-started/generating-starter-app/).\n\n### Automate everything with GitOps \n\nIf you want to adopt a pure GitOps approach we have demonstrated how to use\nArgoCD (OpenShift GitOps) to deploy an Event Streams cluster and maintain it states\nin a simple real time inventory demonstration in [this repository](https://github.com/ibm-cloud-architecture/rt-inventory-gitops).   \n\n\n## Methodology: getting started on a good path\n\nWe have adopted the [Event Storming workshop](/methodology/event-storming) to discover the business process from an event point of view,\nand then apply [domain-driven design](/methodology/domain-driven-design) practices to discover aggregate, business entities, commands, actors and bounded contexts.\nBounded context helps to define microservice and business services scope. Below is a figure to illustrate the DDD elements used during \nthose workshops:\n\n![](../../methodology/event-storming/images/evt-stm-oneview.png)\n\nBounded context map define the solution. Using a lean startup\napproach, we focus on defining a minimum viable product, and preselect a set of services to implement.\n\nWe have detailed how we apply this methodology for a [Vaccine delivery solution](https://ibm-cloud-architecture.github.io/vaccine-solution-main/) \nin [this article](https://ibm-cloud-architecture.github.io/vaccine-solution-main/design/dtw/) which can help you understand how to use the method for your own project.\n\n\n## Frequently asked questions\n\nA [separate FAQ document](/technology/faq) groups the most common questions around Kafka.","type":"Mdx","contentDigest":"4e0f993ed2e9d0f2be3fc40921e7ef62","owner":"gatsby-plugin-mdx","counter":908},"frontmatter":{"title":"Learning Journey - getting started (101 content)","description":"Learning the Basic of Event Streams, Event Driven Solution"},"exports":{},"rawBody":"---\ntitle: Learning Journey - getting started (101 content)\ndescription: Learning the Basic of Event Streams, Event Driven Solution\n---\n\n<InlineNotification kind=\"warning\">\n<strong>Updated 10/12/2021 - Ready for consumption - Open Issue for request for improvement</strong>\n</InlineNotification>\n\nThis chapter is to get you understanding what is Event-Driven architecture,\nwhat is Kafka, how to consider Messaging as a service as a foundation for\nevent-driven solution, and getting started on IBM Event Streams and IBM MQ.\n\n<AnchorLinks>\n  <AnchorLink>Important concepts around Event-driven solution and Event-driven architecture</AnchorLink>\n  <AnchorLink>Understand Kafka technology</AnchorLink>\n  <AnchorLink>So what is IBM Event Streams?</AnchorLink>\n  <AnchorLink>Use Cases</AnchorLink>\n  <AnchorLink>Why microservices are becoming event-driven and why we should care?</AnchorLink>\n  <AnchorLink>Messaging as a service?</AnchorLink>\n  <AnchorLink>Fit for purpose</AnchorLink>\n  <AnchorLink>Event Streams environment sizing</AnchorLink>\n  <AnchorLink>Getting Started With Event Streams</AnchorLink>\n  <AnchorLink>Methodology: getting started on a good path</AnchorLink>\n  <AnchorLink>Frequently asked questions</AnchorLink>\n</AnchorLinks>\n\n## Important concepts around Event-driven solution and Event-driven architecture\n\nFirst to get an agreement on the [terms and definitions](/concepts/terms-and-definitions/) used in all \nthis body of knowledge content, with a clear definitions for `events`, `event streams`, `event backbone`, `event sources`....\n\nThe main up-to-date [reference architecture presentation is in this section](/introduction/reference-architecture/#event-driven-architecture) with all the component descriptions.\n\n ![hl-arch-ra](../../images/hl-arch-ra.png)\n\n\nThis architecture is built after a lot of customer engagements, projects, and review, and \nit is driven to support the [main technical most common use cases](/introduction/usecases/) \nwe observed for EDA adoption so far.\n\n## Understand Kafka technology\n\nYou may want to read from the [Kafka] documentation](https://kafka.apache.org/documentation/#intro_nutshell) to understand the main concepts, but we have\nalso summarized those into [this chapter](/technology/kafka-overview/) and if you like quick \nvideo, here is a seven minutes review of what Kafka is:\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/aj9CDZm0Glc\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n\nThe major building blocks are summarized in this diagram:\n\n![](./images/kafka-components.png)\n\nTo learn more about:\n\n* Kafka Cluster see [this 101 content](/technology/kafka-overview/#kafka-components)\n* For Producer introduction [see this section](/technology/kafka-producers/#understanding-kafka-producers)\n* For Consumer introduction [see this section](/technology/kafka-consumers/)\n* For [Kafka Connector framework introduction](/technology/kafka-connect/)\n\n## So what is IBM Event Streams?\n\nEvent Streams is the IBM packaging of Kafka for the Enterprise. It uses an award winner integrated user interface, kubernetes operator based on open source Strimzi, \nschema registry based on OpenSource and connectors. \nThe phylosophie is to bring together Open Source leading products to support event streaming solution developments on kubernetes platform. \nCombined with event-end point management, no-code integration and IBM MQ, Event Streams brings Kafka to the enterprise.\n\nIt is available as [a Managed Service](https://www.ibm.com/cloud/event-streams)\nor as part of Cloud Pak for integration. [See this developer.ibm.com article about Event Streams on Cloud](https://developer.ibm.com/articles/event-streams-fundamentals/?mhsrc=ibmsearch_a&mhq=ibm%20event%20streams) \nfor a quick introduction.\n\nThe Event Streams product documentation as part of **IBM Cloud Pak for Integration** is [here](https://ibm.github.io/event-streams/about/overview/).\n\n### Runnable demonstrations\n\n* You can install the product using the Operator Hub, IBM Catalog and the OpenShift console. \n[This lab](/technology/event-streams/es-cp4i/#install-event-streams-using-openshift-console) can help you get an environment up and running quickly.\n* You can then run the **Starter Application** as explained in [this tutorial](/technology/event-streams/es-cp4i/#run-starter-application). \n* You may need to demonstrate how to deploy Event Streams with CLI, and [this lab](/technology/event-streams/es-cp4i/#install-event-streams-using-clis) will teach you how to leverage our gitops repository\n* To go deeper in GitOps adoption and discussion, [this tutorial](/use-cases/gitops/) is using two public repositories to demonstrate how to do the automatic deployment of event streams\nand an event-driven solution.\n* Run a simple Kafka Streams and Event Stream demo for [real-time inventory](/scenarios/realtime-inventory/) using this demonstration scripts and GitOps repository.\n\n### Event streams resource requirements\n\nSee the [detailed tables](https://ibm.github.io/event-streams/installing/prerequisites/#helm-resource-requirements) in the product documentation.\n\n### Event Streams environment sizing\n\nA lot of information is available for sizing:\n\n* [Cloud Pak for integration system requirements](https://www.ibm.com/docs/en/cloud-paks/cp-integration/2021.3?topic=installation-system-requirements)\n* [Foundational service specifics](https://www.ibm.com/docs/en/cloud-paks/cp-integration/2021.3?topic=requirements-sizing-foundational-services)\n* [Event Streams resource requirements](https://ibm.github.io/event-streams/installing/prerequisites/)\n* Kafka has a [sizing tool (eventsizer)](https://eventsizer.io/) that may be questionable but some people are using it.\n\nBut in general starts small and then increase the number of nodes over time.\n\nMinimum for production is 5 brokers and 3 zookeepers.\n \n\n## Use Cases\n\nWe have different level of use cases in this repository: \n\nThe generic use cases which present the main drivers for EDA adoption are [summarized here](/introduction/usecases/). \n\nBut architects need to search and identify a set of key requirements to be supported by thier own EDA:\n\n* get visibility of the new data created by existing applications in near real-time to get better business insights and propose new business opportunities to the end-users / customers. \nThis means adopting data streaming, and intelligent query solutions.\n* integrate with existing transactional systems, and continue to do transaction processing while adopting eventual data consistency, characteristics of distributed systems. (Cloud-native serverless or microservices are distributed systems)\n* move to asynchronous communication between serverless and microservices, so they become more responsive, resilient, and scalable (characteristics of ‘Reactive applications’).\n* get loosely coupled but still understand the API contracts. API being synchronous (RES, SOAP) or async (queue and topic).\n* get clear visibility of data governance, with cataloging applications to be able to continuously assess which apps securely access what, with what intent.\n\n\nWe have done some reference implementations to illustrate the major EDA design patterns:\n\n| Scenario                           | Description         | Link        |\n| --------------------------------| ------------------  |:----------- |\n| Shipping fresh food over sea _(external)_ | The EDA solution implementation using event driven microservices in different language, and demonstrating different design patterns. | [EDA reference implementation solution](https://ibm-cloud-architecture.github.io/refarch-kc/)|\n| Vaccine delivery at scale _(external)_ | An EDA and cross cloud pak solution | [Vaccine delivery at scale](https://ibm-cloud-architecture.github.io/vaccine-solution-main/)\n| Real time anomaly detection _(external)_ | Develop and apply machine learning predictive model on event streams | [Refrigerator container anomaly detection solution](https://ibm-cloud-architecture.github.io/refarch-reefer-ml/)|\n\n## Why microservices are becoming event-driven and why we should care?\n\nThis [article](/advantages/microservice) explains why microservices are becoming event-driven \nand relates to some design patterns and potential microservice code structure.\n\n## Messaging as a service? \n\nYes EDA is not just Kafka, IBM MQ and Kafka should be part of any serious EDA deployment.\nThe main reasons are explained in [this fit for purpose section](/concepts/fit-to-purpose/#mq-versus-kafka) and in\nthe [messaging versus eventing presentation](/concepts/events-versus-messages/).\n\nAn introduction to MQ is summarized in [this note](/technology/mq/) in the 301 learning journey, developers need to get the [MQ developer badge](https://developer.ibm.com/learningpaths/ibm-mq-badge/)\nas it cover the basics for developing solution on top of MQ Broker.\n\n## Fit for purpose\n\nWe have a [general fit for purpose document](/concepts/fit-to-purpose/) that can help you reviewing messaging versus eventing,\nMQ versus Kafka, but also Kafka Streams versus Apache Flink.\n\n\n## Getting Started With Event Streams\n\n### With IBM Cloud\n\nThe most easy way to start is to create one `Event Streams on IBM Cloud` service instance,\nand then connect a starter application. See this [service at this URL](https://cloud.ibm.com/catalog/services/event-streams).\n\n### Running on you laptop\n\nAs a **developer**, you may want to start quickly playing with a local Kafka Broker and MQ Broker \non you own laptop. We have developed such compose files in [this gitops project](https://github.com/ibm-cloud-architecture/eda-gitops-catalog) under\nthe `RunLocally` folder.\n\n  ```sh\n  # Kafka based on strimzi image and MQ container\n  docker-compose -f maas-compose.yaml up &\n  # Kafka only\n  docker-compose -f kafka-compose.yaml up &\n  ```\nThe kafka images are based on Strimzi images, but act as Event Streams one. So any code developed and configured\non this image will run the same when deployed on OpenShift using Event Streams.\n\n### Running on OpenShift\n\nFinally if you have access to an OpenShift Cluster, version 4.7 +, you can deploy \nEvent Streams as part of IBM Cloud Pak for Integration very easily using the\nOpenShift Admin console.\n\nSee this simple [step by step tutorial here](/technology/event-streams/es-cp4i/) which covers\nhow to deployment and configuration an Event Streams cluster using the OpenShift Admin\n Console or the `oc CLI` and our manifest from our [EDA gitops catalog repository](https://github.com/ibm-cloud-architecture/eda-gitops-catalog).\n\n### Show and tell \n\nOnce you have deployed a cluster, access the administration console and use the\nvery good [getting started application](https://ibm.github.io/event-streams/getting-started/generating-starter-app/).\n\n### Automate everything with GitOps \n\nIf you want to adopt a pure GitOps approach we have demonstrated how to use\nArgoCD (OpenShift GitOps) to deploy an Event Streams cluster and maintain it states\nin a simple real time inventory demonstration in [this repository](https://github.com/ibm-cloud-architecture/rt-inventory-gitops).   \n\n\n## Methodology: getting started on a good path\n\nWe have adopted the [Event Storming workshop](/methodology/event-storming) to discover the business process from an event point of view,\nand then apply [domain-driven design](/methodology/domain-driven-design) practices to discover aggregate, business entities, commands, actors and bounded contexts.\nBounded context helps to define microservice and business services scope. Below is a figure to illustrate the DDD elements used during \nthose workshops:\n\n![](../../methodology/event-storming/images/evt-stm-oneview.png)\n\nBounded context map define the solution. Using a lean startup\napproach, we focus on defining a minimum viable product, and preselect a set of services to implement.\n\nWe have detailed how we apply this methodology for a [Vaccine delivery solution](https://ibm-cloud-architecture.github.io/vaccine-solution-main/) \nin [this article](https://ibm-cloud-architecture.github.io/vaccine-solution-main/design/dtw/) which can help you understand how to use the method for your own project.\n\n\n## Frequently asked questions\n\nA [separate FAQ document](/technology/faq) groups the most common questions around Kafka.","fileAbsolutePath":"/home/runner/work/refarch-eda/refarch-eda/docs/src/pages/journey/101/index.mdx"}}},"staticQueryHashes":["1364590287","137577622","137577622","2102389209","2102389209","2456312558","2746626797","2746626797","3018647132","3018647132","3037994772","3037994772","768070550"]}